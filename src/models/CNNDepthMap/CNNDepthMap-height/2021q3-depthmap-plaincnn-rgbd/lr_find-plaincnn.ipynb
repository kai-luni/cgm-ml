{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "import glob2 as glob\n",
    "import tensorflow as tf\n",
    "from azureml.core import Experiment, Workspace\n",
    "from azureml.core.run import Run\n",
    "from tensorflow.keras import callbacks\n",
    "\n",
    "sys.path.append(str(Path(os.getcwd()) / 'src'))\n",
    "\n",
    "from config import CONFIG\n",
    "from constants import REPO_DIR, NUM_INPUT_CHANNELS\n",
    "\n",
    "sys.path.append(str(REPO_DIR / 'src/common'))\n",
    "\n",
    "from model_utils.model_plaincnn import create_cnn\n",
    "from model_utils.preprocessing import preprocess_depthmap, preprocess_targets\n",
    "from model_utils.lr_finder import LRFinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make experiment reproducible\n",
    "tf.random.set_seed(CONFIG.SPLIT_SEED)\n",
    "random.seed(CONFIG.SPLIT_SEED)\n",
    "\n",
    "# Get the current run.\n",
    "run = Run.get_context()\n",
    "\n",
    "# Offline run. Download the sample dataset and run locally. Still push results to Azure.\n",
    "if(run.id.startswith(\"OfflineRun\")):\n",
    "    print(\"Running in offline mode...\")\n",
    "\n",
    "    # Access workspace.\n",
    "    print(\"Accessing workspace...\")\n",
    "    workspace = Workspace.from_config()\n",
    "    experiment = Experiment(workspace, \"training-junkyard\")\n",
    "    run = experiment.start_logging(outputs=None, snapshot_directory=None)\n",
    "\n",
    "    # Get dataset.\n",
    "    print(\"Accessing dataset...\")\n",
    "    dataset_name = CONFIG.DATASET_NAME_LOCAL  # .DATASET_NAME  # DATASET_NAME_LOCAL\n",
    "    dataset_path = str(REPO_DIR / \"data\" / dataset_name)\n",
    "    if not os.path.exists(dataset_path):\n",
    "        dataset = workspace.datasets[dataset_name]\n",
    "        dataset.download(target_path=dataset_path, overwrite=False)\n",
    "\n",
    "# Online run. Use dataset provided by training notebook.\n",
    "else:\n",
    "    print(\"Running in online mode...\")\n",
    "    experiment = run.experiment\n",
    "    workspace = experiment.workspace\n",
    "    dataset_path = run.input_datasets[\"dataset\"]\n",
    "    \n",
    "dataset_path = os.path.join(dataset_path, \"qrcode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the QR-code paths.\n",
    "\n",
    "print(\"Dataset path:\", dataset_path)\n",
    "#print(glob.glob(os.path.join(dataset_path, \"*\"))) # Debug\n",
    "print(\"Getting QR-code paths...\")\n",
    "qrcode_paths = glob.glob(os.path.join(dataset_path, \"*\"))\n",
    "print(\"qrcode_paths: \", len(qrcode_paths))\n",
    "assert len(qrcode_paths) != 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle and split into train and validate.\n",
    "random.shuffle(qrcode_paths)\n",
    "split_index = int(len(qrcode_paths) * 0.8)\n",
    "qrcode_paths_training = qrcode_paths[:split_index]\n",
    "\n",
    "# Show split.\n",
    "print(\"Paths for training:\")\n",
    "print(\"\\t\" + \"\\n\\t\".join(qrcode_paths_training))\n",
    "print(len(qrcode_paths_training))\n",
    "\n",
    "assert len(qrcode_paths_training) > 0\n",
    "\n",
    "def get_depthmap_files(paths):\n",
    "    pickle_paths = []\n",
    "    for path in paths:\n",
    "        pickle_paths.extend(glob.glob(os.path.join(path, \"**\", \"*.p\")))\n",
    "    return pickle_paths\n",
    "\n",
    "\n",
    "# Get the pointclouds.\n",
    "print(\"Getting depthmap paths...\")\n",
    "paths_training = get_depthmap_files(qrcode_paths_training)\n",
    "\n",
    "print(\"Using {} files for training.\".format(len(paths_training)))\n",
    "\n",
    "# Function for loading and processing depthmaps.\n",
    "# def tf_load_pickle(path, max_value):\n",
    "#     def py_load_pickle(path, max_value):\n",
    "#         rgbd, targets = pickle.load(open(path.numpy(), \"rb\"))\n",
    "#         rgb = rgbd[0]  # shape: (240, 180, 3)\n",
    "#         depthmap = rgbd[1]  # shape: (240, 180)\n",
    "\n",
    "#         rgb = preprocess_depthmap(rgb)\n",
    "#         rgb = rgb / 255.\n",
    "\n",
    "#         depthmap = preprocess_depthmap(depthmap)\n",
    "#         depthmap = depthmap / max_value\n",
    "#         depthmap = tf.expand_dims(depthmap, -1)    # shape: (240, 180, 1)\n",
    "\n",
    "#         rgbd = tf.concat([rgb, depthmap], axis=2)\n",
    "#         rgbd = tf.image.resize(rgbd, (CONFIG.IMAGE_TARGET_HEIGHT, CONFIG.IMAGE_TARGET_WIDTH))\n",
    "#         targets = preprocess_targets(targets, CONFIG.TARGET_INDEXES)\n",
    "#         return rgbd, targets\n",
    "\n",
    "#     rgbd, targets = tf.py_function(py_load_pickle, [path, max_value], [tf.float32, tf.float32])\n",
    "#     rgbd.set_shape((CONFIG.IMAGE_TARGET_HEIGHT, CONFIG.IMAGE_TARGET_WIDTH, 4))\n",
    "#     targets.set_shape((len(CONFIG.TARGET_INDEXES,)))\n",
    "#     return rgbd, targets\n",
    "\n",
    "def tf_load_pickle(path, max_value):\n",
    "    def py_load_pickle(path, max_value):\n",
    "        rgbd, targets = pickle.load(open(path.numpy(), \"rb\"))\n",
    "        rgb = rgbd[0]  # shape: (240, 180, 3)\n",
    "        depthmap = rgbd[1]  # shape: (240, 180)\n",
    "\n",
    "        rgb = preprocess_depthmap(rgb)\n",
    "        rgb = rgb / 255.\n",
    "\n",
    "        depthmap = preprocess_depthmap(depthmap)\n",
    "        depthmap = depthmap / max_value\n",
    "        depthmap = tf.expand_dims(depthmap, -1)  # shape: (240, 180, 1)\n",
    "        rgbd = tf.concat([rgb, depthmap], axis=2)\n",
    "        rgbd = tf.image.resize(rgbd, (CONFIG.IMAGE_TARGET_HEIGHT, CONFIG.IMAGE_TARGET_WIDTH))\n",
    "        targets = preprocess_targets(targets, CONFIG.TARGET_INDEXES)\n",
    "        return rgbd, targets\n",
    "\n",
    "    rgbd, targets = tf.py_function(py_load_pickle, [path, max_value], [tf.float32, tf.float32])\n",
    "    rgbd.set_shape((CONFIG.IMAGE_TARGET_HEIGHT, CONFIG.IMAGE_TARGET_WIDTH, NUM_INPUT_CHANNELS))\n",
    "    targets.set_shape((len(CONFIG.TARGET_INDEXES,)))\n",
    "    return rgbd, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset for training.\n",
    "paths = paths_training\n",
    "dataset = tf.data.Dataset.from_tensor_slices(paths)\n",
    "dataset_norm = dataset.map(lambda path: tf_load_pickle(path, CONFIG.NORMALIZATION_VALUE))\n",
    "dataset_norm = dataset_norm.cache()\n",
    "dataset_norm = dataset_norm.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "dataset_norm = dataset_norm.shuffle(CONFIG.SHUFFLE_BUFFER_SIZE)\n",
    "dataset_training = dataset_norm\n",
    "del dataset_norm\n",
    "# Note: Now the datasets are prepared.\n",
    "\n",
    "# Create the model.\n",
    "input_shape = (CONFIG.IMAGE_TARGET_HEIGHT, CONFIG.IMAGE_TARGET_WIDTH, NUM_INPUT_CHANNELS)\n",
    "model = create_cnn(input_shape, dropout=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=\"mse\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LR Find"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_finder = LRFinder(start_lr=1e-4)\n",
    "_ = model.fit(dataset_training.batch(CONFIG.BATCH_SIZE), epochs=20, callbacks=[lr_finder], verbose=2)\n",
    "lr_finder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "IGNORE = 40\n",
    "# aaa = list(zip(lr_finder.lrs[:IGNORE], lr_finder.losses[:IGNORE]))\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_xlabel('Learning Rate (log scale)')\n",
    "ax.set_xscale('log')\n",
    "ax.xaxis.set_major_formatter(plt.FormatStrFormatter('%.0e'))\n",
    "ax.plot(lr_finder.lrs[:-IGNORE], lr_finder.losses[:-IGNORE]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.cla()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_finder = LRFinder(end_lr=3) #0.02290) # otherwise plot looks unusable \n",
    "_ = model.fit(dataset_training.batch(CONFIG.BATCH_SIZE), epochs=5, callbacks=[lr_finder], verbose=2)\n",
    "lr_finder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_finder = LRFinder(end_lr=0.3) #0.02290) # otherwise plot looks unusable \n",
    "_ = model.fit(dataset_training.batch(CONFIG.BATCH_SIZE), epochs=5, callbacks=[lr_finder], verbose=2)\n",
    "lr_finder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LRFinder??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lr_finder.losses)\n",
    "axes = plt.gca()\n",
    "# axes.set_xlim([xmin,xmax])\n",
    "axes.set_ylim([4000,9000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_finder.lrs[63]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(lr_finder.lrs, lr_finder.losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.5 64-bit ('env_p_3': virtualenvwrapper)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "pygments_lexer": "ipython3",
  "version": 3,
  "interpreter": {
   "hash": "e88cacac4a4e81780274e5b67662f71286bfdfe71b49b67699dc84b91a2b06f4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}